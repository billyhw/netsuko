% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/netzuko.R
\name{predict.netzuko}
\alias{predict.netzuko}
\title{Make Predictions on a test set}
\usage{
\method{predict}{netzuko}(nn_fit, newdata, type = c("prob", "class"))
}
\arguments{
\item{nn_fit}{A fitted neural network object from netzuko}

\item{newdata}{The test inputs}

\item{type}{The output type. When type = "prob" (default) the output is a matrix of class
probabilities. When type = "class", the output is the class with the highest predictive probability}
}
\value{
A matrix of output probabilities
}
\description{
Make Predictions on a test set
}
\note{
This function is essentially the forward pass of a neural network.
}
\examples{
set.seed(8)
logistic = function(alpha, beta, x) 1/(1 + exp(-(alpha + beta*x)))
x_train = matrix(rnorm(300), 100, 3)
y_train = factor(rbinom(100, 1, prob = logistic(alpha = 0, beta = 1, x_train[,1])) +
                  rbinom(100, 1, prob = logistic(alpha = 0, beta = 1, x_train[,2])))
x_test = matrix(rnorm(3000), 1000, 3)
y_test = factor(rbinom(1000, 1, prob = logistic(alpha = 0, beta = 1, x_test[,1])) +
                 rbinom(1000, 1, prob = logistic(alpha = 0, beta = 1, x_test[,2])))
fit = netzuko(x_train, y_train, x_test, y_test, num_hidden = c(3, 3), step_size = 0.01, iter = 100)
pred = predict(fit, x_test)
fit$cost_test[100]
-mean(rowSums(model.matrix(~ y_test - 1)*log(pred))) # negative cross entropy
\dontrun{
fit_2 = netzuko(mnist$x_train[1:1000,], mnist$y_train[1:1000],
num_hidden = 100, step_size = 0.01, iter = 100, sparse = T)
pred_2 = predict(fit_2, mnist$x_train[1001:2000,], type = "class")
mean(pred_2 == mnist$y_train[1001:2000])
}
}
