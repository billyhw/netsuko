% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/netzuko.R
\name{predict.netzuko}
\alias{predict.netzuko}
\title{Make Predictions on a test set}
\usage{
\method{predict}{netzuko}(nn_fit, newdata, type = c("prob", "class"))
}
\arguments{
\item{nn_fit}{A fitted neural network object from netzuko}

\item{newdata}{The test inputs}

\item{type}{The output type. When type = "prob" (default) the output is a matrix of class
probabilities. When type = "class", the output is the class with the highest predictive probability}
}
\value{
A matrix of output probabilities
}
\description{
Make Predictions on a test set
}
\note{
This function is essentially the forward pass of a neural network.
}
\examples{
set.seed(8)
logistic = function(alpha, beta, x) 1/(1 + exp(-(alpha + beta*x)))
x_train = matrix(rnorm(300), 100, 3)
y_train = factor(rbinom(100, 1, prob = logistic(alpha = 0, beta = 1, x_train[,1])) +
                  rbinom(100, 1, prob = logistic(alpha = 0, beta = 1, x_train[,2])))
x_test = matrix(rnorm(3000), 1000, 3)
y_test = factor(rbinom(1000, 1, prob = logistic(alpha = 0, beta = 1, x_test[,1])) +
                 rbinom(1000, 1, prob = logistic(alpha = 0, beta = 1, x_test[,2])))
fit = netzuko(x_train, y_train, x_test, y_test, num_hidden = c(3, 3), step_size = 0.01, iter = 100)
pred = predict(fit, x_test)
fit$cost_test[100]
-mean(rowSums(model.matrix(~ y_test - 1)*log(pred))) # negative cross entropy
y_train = factor(rbinom(100, 1, prob = logistic(alpha = 0, beta = 1, x_train[,1])))
y_test = factor(rbinom(1000, 1, prob = logistic(alpha = 0, beta = 1, x_test[,1])))
fit_2 = netzuko(x_train[,1], y_train, x_test[,1], y_test, iter = 100, num_hidden = 2)
pred_2 = predict(fit_2, x_test[,1])
fit_2$cost_test[100]
-mean(rowSums(model.matrix(~ y_test - 1)*log(pred_2))) # negative cross entropy
x_train = matrix(rnorm(300), 100, 3)
y_train = x_train[,1]^2
x_test = matrix(rnorm(3000), 1000, 3)
y_test = x_test[,1]^2
fit_3 = netzuko(x_train, y_train, x_test, y_test, step_size = 0.003, iter = 100)
pred_3 = predict(fit_3, x_test)
fit_3$cost_test[100]
mean((y_test - pred_3)^2)/2 # halved mean square error
\dontrun{
fit_4 = netzuko(mnist$x_train[1:1000,], mnist$y_train[1:1000],
num_hidden = 100, step_size = 0.01, iter = 100, sparse = T)
pred_4 = predict(fit_4, mnist$x_train[1001:2000,], type = "class")
mean(pred_4 == mnist$y_train[1001:2000])
}
}
